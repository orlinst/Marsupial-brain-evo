output$SD <- NULL
output$`Naive SE` <- NULL
output$`Time-series SE` <- NULL
return(output)
}
## Run the functions and get *results*
all_Sol <- lapply(raw_models_allchains, get.Sol)
all_summaries <- lapply(raw_models_allchains, get.summary.Sol)
results <- lapply(all_summaries, get.stat.Sol)
#setwd("./")
#using list.rbind from rlist
solX <- as.data.frame(list.rbind(all_Sol))
names(solX)
names(solX) <- c("Intercept", "Torpor", "Body Size", "Torpor:Body Size")
#env
# ("Intercept", "Diurnal", "Crepuscular", "Shelter Safety - intermediate", "Shelter Safety - open", "Terrestrial", "Diet - 2", "Diet - 3", "Diet - 4", "Home Range", "Body Size")
#dev
# ("Intercept", "Body Size", "Weaning Age", "Litter Size")
#fmr
# ("Intercept", "FMR", "Body Size", "FMR : Body Size")
#ori
# ("Intercept", "Origin -2", "Origin - 3", "Body Size", "Origin - 2:Body Size", "Origin - 3:Body Size")
#play
# ("Intercept", "Play -2", "Play - 3", "Body Size", "Play - 2:Body Size", "Play - 3:Body Size")
#soc
# ("Intercept", "Group Living", "Parental Care", "Mating System", "Population Density", "Body Size")
#tor
# ("Intercept", "Torpor", "Body Size", "Torpor:Body Size")
#vul
# ("Intercept", "Status - 2", "Status - 3", "Body Size", "Status - 2:Body Size", "Status - 3:Body Size" )
#soc2
#("Intercept", "Population density",  "Home Range", "Body Size")
#soc3
#("Intercept",    "Parental Care", "Mating System", "Body Size")
#plot in pdf
pdf(file="./MCMCmodels/density.pdf")
par( mfrow = c( 3, 3 ))
#dens.plot <- plot()
for(column in 1 : c(ncol(solX))) {
percentage_above_zero <- length(which(solX[,column] >= 0))/length(solX[,column])
hdr.den(solX[,column],  main = names(solX[column]), sub = paste0(round(percentage_above_zero*100,2), "% above zero"), prob = c(50, 95, 99))
abline(v = 0, lty = 1)
}
dev.off()
#beta_density <- density(solX$FMR.Riek)
#plot(beta_density)
#abline(v = 0, lty = 2)
#percentage_above_zero <- length(which(solX$FMR.Riek >= 0))/length(solX$FMR.Riek)
#percentage_above_zero
# Using the posteriors collated in *results*
mbar <-  function (x, col=1) { # function to calculate average parameter estimates and average variances from the results list
vals <- rowMeans(matrix(unlist(lapply(x, function (z) z[, col])),
nrow=dim(x[[1]])[1], ncol=length(x)))
names(vals) <- rownames(x[[1]])
vals
}
Bm <- function (x) {
Qmbar <- mbar(x)
Qvals <- matrix(unlist(lapply(x, function (z) z[,1])),
ncol=length(x), nrow=dim(x[[1]])[1])
QQ <- apply(Qvals, 2, function (x) x - Qmbar)
apply(QQ, 1, function (z) (z %*% z)/(length(z)-1))
}
Tm <- function (x) {
Umbar <- mbar(x,  col=2)
Umbar + (1 + 1/length(x)) * Bm(x)
}
lambda <- function (nu) {
(nu + 1)/(nu + 3)
}
vm <- function (Bm, Tm, m=5){
gammahat <- (1+1/m) * sum(Bm/Tm)/length(Bm)
(m-1)/(gammahat^2)
}
# Now we do the analysis:
#m - imputed sets * chains
#n - number of species
#k - number of params as N of cols in solutions
m <- (length(imp$imp[[1]]))*2
n <- 176
k <- ncol(solX)
## m = number of imputed datasets
## n = number of observations
## k = number of parameters
Bm1 <- Bm(results)
Tm1 <- Tm(results) # total variance
# calculation of the degrees of freedom for t-tests of parameters
vhatobs <- lambda(n-k)*(n-k)*(1- (1+1/m) * sum(Bm1/Tm1)/length(Bm1))
vm1 <- vm(Bm1, Tm1)
vmtilde <-  1/(1/vm1+1/vhatobs)
Qmbar <- mbar(results) # mean parameter estimates
WaldT <- Qmbar/sqrt(Tm1)
upperCI <- Qmbar + sqrt(Tm1) * qt(.95, vmtilde)
lowerCI <-  Qmbar - sqrt(Tm1) * qt(.95, vmtilde)
tTable <- cbind(Qmbar, SE=sqrt(Tm1), WaldT,
df=vmtilde, p=2*(1-pt(abs(WaldT),
vmtilde)), lowerCI, upperCI)
#Getting DICs and averaging (possibly other ICs)
get.DIC <- function(model) {return(model$DIC)}
model_DICs <- lapply(raw_models_allchains, get.DIC)
model_DICs <- as.data.frame(model_DICs)
DICnames <- c(paste0("Model", 1:ncol(model_DICs)))
colnames(model_DICs) <- DICnames
DICs <- mean(t(model_DICs))
DICs
#Calculating average H for all models
get.H <- function(model) {return((var(model$VCV[,"animal"]))/
+     (var(model$VCV[,"animal"]) + var(model$VCV[,"units"])))
}
Hs <- lapply(raw_models_allchains, get.H)
Hs <- as.data.frame(Hs)
mean(t(Hs))
#Change row names
row.names(tTable)
row.names(tTable) <- names(solX)
#Export a csv table
#col.names = NA offsets the header with 1
write.table(as.matrix(tTable), "./MCMCmodels/analysis-output.csv", sep = ",", col.names = NA, row.names = TRUE)
#Export txt with posteriors and Hs and DICs
sink('./MCMCmodels/analysis-output.txt')
#options(width=10000) stops word wrapping
options(width=10000)
#print pooled results
tTable
#print Hs
print("Mean H")
mean(t(Hs))
#print DICs
print("Mean DIC")
DICs
sink()
#Convert data to res.plot
res.plot <- as.data.frame(tTable)
#res.plot$upperCI <- NULL
#res.plot$lowerCI <- NULL
res.plot$p <- NULL
res.plot$df <- NULL
res.plot$WaldT <- NULL
#generate pdf with the model
pdf(file="./MCMCmodels/model.pdf",width=6,height=4)
p <- ggplot(
res.plot,
aes(x = Qmbar, y = fct_relevel(row.names(res.plot), "Body Size", "Intercept", after = Inf), xmin = lowerCI, xmax = upperCI)) +
geom_point(aes(color = row.names(res.plot))) +
geom_errorbarh(aes(color = row.names(res.plot)), height=0.05)+
geom_vline(xintercept = 0, color = "red", linetype="longdash", size=0.5) +
theme_light()
p$labels$colour <- "Model parameters"
p$labels$x <- "Posterior estimate + 95% CI"
p$labels$y <- "Model parameters"
p
#fct_relevel(row.names(res.plot), "Body Size", "Intercept", after = Inf)
#generates bayesplot of the model
color_scheme_set("brightblue")
mcmc_intervals(t(res.plot))
dev.off()
#optional
mcmc_areas(t(res.plot))
#Set WD to the model of interest
#Load imp if not loaded, as it is used for the count of the number of imputed sets
#setwd("./MCMCmodels")
#Reading all models + all chains (if more chains are run, add manually here)
#setwd("C:/Users/uqotodor_local/Dropbox/05. Github/Marsupial-brain-evo/MCMCmodels/model_dev")
setwd("C:/Users/uqotodor_local/Dropbox/05. Github/Marsupial-brain-evo/MCMCmodels/model_vul")
list() -> raw_models_chain1 -> raw_models_chain2
for(imputedsets in 1:  length(imp$imp[[1]])) {
raw_models_chain1[[imputedsets]] <- read.mulTree(paste0("model",imputedsets,"-tree1_chain1"), model = TRUE)
raw_models_chain2[[imputedsets]] <- read.mulTree(paste0("model",imputedsets,"-tree1_chain2"), model = TRUE)
}
raw_models_allchains <- c(raw_models_chain1, raw_models_chain2)
## Get Sol
# @param model this should be a single model (e.g. one chain output from mcmcglmm)
# @return the Sol vector from one single chain
get.Sol <- function(model) {return(model$Sol)}
## Get summary of Sol
# @param model this should be a single model (e.g. one chain output from mcmcglmm)
# @return the summary table of the Sol
get.summary.Sol <- function(model) {return(summary(model$Sol))}
## Turn into dataframe and get statistics
## obtain Variance (SD^2) and bind to the list
## remove unnecessary columns
# @param The output of get.summary.Sol (the summary of Sol)
# @return dataframe with statistics
get.stat.Sol <- function(summarySol) {
output <- as.data.frame(summarySol$statistics)
output$Var <- (output$SD)^2
output$SD <- NULL
output$`Naive SE` <- NULL
output$`Time-series SE` <- NULL
return(output)
}
## Run the functions and get *results*
all_Sol <- lapply(raw_models_allchains, get.Sol)
all_summaries <- lapply(raw_models_allchains, get.summary.Sol)
results <- lapply(all_summaries, get.stat.Sol)
#setwd("./")
names(solX)
names(solX) <- c("Intercept", "Status - 2", "Status - 3", "Body Size", "Status - 2:Body Size", "Status - 3:Body Size" )
#using list.rbind from rlist
solX <- as.data.frame(list.rbind(all_Sol))
names(solX)
names(solX) <- c("Intercept", "Status - 2", "Status - 3", "Body Size", "Status - 2:Body Size", "Status - 3:Body Size" )
#env
# ("Intercept", "Diurnal", "Crepuscular", "Shelter Safety - intermediate", "Shelter Safety - open", "Terrestrial", "Diet - 2", "Diet - 3", "Diet - 4", "Home Range", "Body Size")
#dev
# ("Intercept", "Body Size", "Weaning Age", "Litter Size")
#fmr
# ("Intercept", "FMR", "Body Size", "FMR : Body Size")
#ori
# ("Intercept", "Origin -2", "Origin - 3", "Body Size", "Origin - 2:Body Size", "Origin - 3:Body Size")
#play
# ("Intercept", "Play -2", "Play - 3", "Body Size", "Play - 2:Body Size", "Play - 3:Body Size")
#soc
# ("Intercept", "Group Living", "Parental Care", "Mating System", "Population Density", "Body Size")
#tor
# ("Intercept", "Torpor", "Body Size", "Torpor:Body Size")
#vul
# ("Intercept", "Status - 2", "Status - 3", "Body Size", "Status - 2:Body Size", "Status - 3:Body Size" )
#soc2
#("Intercept", "Population density",  "Home Range", "Body Size")
#soc3
#("Intercept",    "Parental Care", "Mating System", "Body Size")
#plot in pdf
pdf(file="./MCMCmodels/density.pdf")
par( mfrow = c( 3, 3 ))
#dens.plot <- plot()
for(column in 1 : c(ncol(solX))) {
percentage_above_zero <- length(which(solX[,column] >= 0))/length(solX[,column])
hdr.den(solX[,column],  main = names(solX[column]), sub = paste0(round(percentage_above_zero*100,2), "% above zero"), prob = c(50, 95, 99))
abline(v = 0, lty = 1)
}
dev.off()
#beta_density <- density(solX$FMR.Riek)
#plot(beta_density)
#abline(v = 0, lty = 2)
#percentage_above_zero <- length(which(solX$FMR.Riek >= 0))/length(solX$FMR.Riek)
#percentage_above_zero
# Using the posteriors collated in *results*
mbar <-  function (x, col=1) { # function to calculate average parameter estimates and average variances from the results list
vals <- rowMeans(matrix(unlist(lapply(x, function (z) z[, col])),
nrow=dim(x[[1]])[1], ncol=length(x)))
names(vals) <- rownames(x[[1]])
vals
}
Bm <- function (x) {
Qmbar <- mbar(x)
Qvals <- matrix(unlist(lapply(x, function (z) z[,1])),
ncol=length(x), nrow=dim(x[[1]])[1])
QQ <- apply(Qvals, 2, function (x) x - Qmbar)
apply(QQ, 1, function (z) (z %*% z)/(length(z)-1))
}
Tm <- function (x) {
Umbar <- mbar(x,  col=2)
Umbar + (1 + 1/length(x)) * Bm(x)
}
lambda <- function (nu) {
(nu + 1)/(nu + 3)
}
vm <- function (Bm, Tm, m=5){
gammahat <- (1+1/m) * sum(Bm/Tm)/length(Bm)
(m-1)/(gammahat^2)
}
# Now we do the analysis:
#m - imputed sets * chains
#n - number of species
#k - number of params as N of cols in solutions
m <- (length(imp$imp[[1]]))*2
n <- 176
k <- ncol(solX)
## m = number of imputed datasets
## n = number of observations
## k = number of parameters
Bm1 <- Bm(results)
Tm1 <- Tm(results) # total variance
# calculation of the degrees of freedom for t-tests of parameters
vhatobs <- lambda(n-k)*(n-k)*(1- (1+1/m) * sum(Bm1/Tm1)/length(Bm1))
vm1 <- vm(Bm1, Tm1)
vmtilde <-  1/(1/vm1+1/vhatobs)
Qmbar <- mbar(results) # mean parameter estimates
WaldT <- Qmbar/sqrt(Tm1)
upperCI <- Qmbar + sqrt(Tm1) * qt(.95, vmtilde)
lowerCI <-  Qmbar - sqrt(Tm1) * qt(.95, vmtilde)
tTable <- cbind(Qmbar, SE=sqrt(Tm1), WaldT,
df=vmtilde, p=2*(1-pt(abs(WaldT),
vmtilde)), lowerCI, upperCI)
#Getting DICs and averaging (possibly other ICs)
get.DIC <- function(model) {return(model$DIC)}
model_DICs <- lapply(raw_models_allchains, get.DIC)
model_DICs <- as.data.frame(model_DICs)
DICnames <- c(paste0("Model", 1:ncol(model_DICs)))
colnames(model_DICs) <- DICnames
DICs <- mean(t(model_DICs))
DICs
#Calculating average H for all models
get.H <- function(model) {return((var(model$VCV[,"animal"]))/
+     (var(model$VCV[,"animal"]) + var(model$VCV[,"units"])))
}
Hs <- lapply(raw_models_allchains, get.H)
Hs <- as.data.frame(Hs)
mean(t(Hs))
#Change row names
row.names(tTable)
row.names(tTable) <- names(solX)
#Export a csv table
#col.names = NA offsets the header with 1
write.table(as.matrix(tTable), "./MCMCmodels/analysis-output.csv", sep = ",", col.names = NA, row.names = TRUE)
#Export txt with posteriors and Hs and DICs
sink('./MCMCmodels/analysis-output.txt')
#options(width=10000) stops word wrapping
options(width=10000)
#print pooled results
tTable
#print Hs
print("Mean H")
mean(t(Hs))
#print DICs
print("Mean DIC")
DICs
sink()
#Convert data to res.plot
res.plot <- as.data.frame(tTable)
#res.plot$upperCI <- NULL
#res.plot$lowerCI <- NULL
res.plot$p <- NULL
res.plot$df <- NULL
res.plot$WaldT <- NULL
#generate pdf with the model
pdf(file="./MCMCmodels/model.pdf",width=6,height=4)
p <- ggplot(
res.plot,
aes(x = Qmbar, y = fct_relevel(row.names(res.plot), "Body Size", "Intercept", after = Inf), xmin = lowerCI, xmax = upperCI)) +
geom_point(aes(color = row.names(res.plot))) +
geom_errorbarh(aes(color = row.names(res.plot)), height=0.05)+
geom_vline(xintercept = 0, color = "red", linetype="longdash", size=0.5) +
theme_light()
p$labels$colour <- "Model parameters"
p$labels$x <- "Posterior estimate + 95% CI"
p$labels$y <- "Model parameters"
p
#fct_relevel(row.names(res.plot), "Body Size", "Intercept", after = Inf)
#generates bayesplot of the model
color_scheme_set("brightblue")
mcmc_intervals(t(res.plot))
dev.off()
#optional
mcmc_areas(t(res.plot))
require(rethinking)
#Loading data, imputed datasets file and tree
data <-read.csv("./Data/marsALL.txt", sep = "\t", header = TRUE)
precis(data)
precis(data)
precis( data )
precis( data )
precis( data )
precis( data )
require(MCMCglmm)
version
require(caper)
require(ape)
require(dispRity)
require(geiger)
require(multcomp)
require(phytools)
require(ape)
require(geiger)
require(nlme)
require(evomap)
require(adephylo)
require(phangorn)
# vifs
require(fmsb) # vifs
#plotting
require(ggplot2)
require(RColorBrewer)
data <-read.csv("./Data/marsALL.txt", sep = "\t", header = TRUE)
tree <-read.tree("./Data/tree176.nwk")
rownames(data) <- data$Names
clean.data(data, tree)  ## check if data == tree names
require(geiger)
require(multcomp)
require(phytools)
require(ape)
require(geiger)
require(nlme)
require(evomap)
require(adephylo)
require(phangorn)
install.packages(c("dispRity", "phangorn", "geiger", "adephylo"))
require(caper)
require(ape)
require(dispRity)
require(geiger)
require(multcomp)
require(phytools)
require(ape)
require(geiger)
require(nlme)
#require(evomap)
require(adephylo)
require(phangorn)
# vifs
require(fmsb) # vifs
#plotting
require(ggplot2)
require(RColorBrewer)
data <-read.csv("./Data/marsALL.txt", sep = "\t", header = TRUE)
tree <-read.tree("./Data/tree176.nwk")
rownames(data) <- data$Names
clean.data(data, tree)  ## check if data == tree names
data <-read.csv("./Data/marsALL.txt", sep = "\t", header = TRUE)
tree <-read.tree("./Data/tree176.nwk")
rownames(data) <- data$Names
clean.data(data, tree)  ## check if data == tree names
data$Order <- as.factor(data$Order)
data$Family <- as.factor(data$Family)
data$Origin <- as.factor(data$Origin)
data$Status <- as.factor(data$Status)
data$DiurnalityN <- as.factor(data$DiurnalityN)
data$Arboreality <- as.factor(data$Arboreality)
data$Shelter.safety <- as.factor(data$Shelter.safety)
data$Diet <- as.factor(data$Diet)
data$Group.living <- as.factor(data$Group.living)
data$Parental.care <- as.factor(data$Parental.care)
data$Mating.system <- as.factor(data$Mating.system)
data$Torpor <- as.factor(data$Torpor)
data$Play <- as.factor(data$Play)
subsetOZ <- data[data$Origin == "1",]
subsetNG <- data[data$Origin == "2",]
subsetAM<- data[data$Origin == "3",]
require(caper)
require(ape)
require(dispRity)
require(geiger)
require(multcomp)
require(phytools)
require(ape)
require(geiger)
require(nlme)
#require(evomap)
require(adephylo)
require(phangorn)
# vifs
require(fmsb) # vifs
#plotting
require(ggplot2)
require(RColorBrewer)
#Create comparative object for ape
mars <- comparative.data(phy = tree, data = data, names.col = Names,
vcv = TRUE, na.omit = FALSE, warn.dropped = TRUE)
####
marsOZ <- comparative.data(phy = tree, data = subsetOZ, names.col = Names,
vcv = TRUE, na.omit = FALSE, warn.dropped = TRUE)
marsNG <- comparative.data(phy = tree, data = subsetNG, names.col = Names,
vcv = TRUE, na.omit = FALSE, warn.dropped = TRUE)
marsAM <- comparative.data(phy = tree, data = subsetAM, names.col = Names,
vcv = TRUE, na.omit = FALSE, warn.dropped = TRUE)
#####
#Allometric slope for residuals
#Slope 0.57
model.pgls.res <- pgls(log(Brain) ~ log(BodyN), data = mars, lambda='ML')
summary(model.pgls.res)
#Obtain kappa so to infer the model of evolution
mars_3d <- comparative.data(phy = tree, data = data, names.col = Names, vcv.dim=3, vcv = TRUE, na.omit = FALSE, warn.dropped = TRUE)
model.pgls.kappa <- pgls(log(Brain) ~ log(BodyN), data = mars_3d, kappa ="ML")
summary (model.pgls.kappa)
#look at the kappa plot
profile_kappa=pgls.profile(model.pgls.kappa, which="kappa")
plot(profile_kappa)
#kappa is estimated around 0.8 (if fixing lambda to 0.91) thus it is close to brownian motion
#load up comp data with the phylogenetic residuals
res<-residuals(model.pgls.res) #phylo=T exports phylo corrected residuals
res<- res/sqrt(var(res))[1] #standartize residuals
#plot and observe that there are no outlies with res>3
par(mfrow=c(2,2))
plot(model.pgls.res)
#binding residuals to the main dataset
data <- cbind (data, res)
mars <- comparative.data(phy = tree, data = data, names.col = Names, vcv = TRUE, na.omit = FALSE, warn.dropped = TRUE)
X <- "Brain"
Y <- "BodyN"
FR <- "Origin"
dat <-data[,c(which(colnames(data)==Y),which(colnames(data)==X), which(colnames(data)==FR) ),drop=F]
colnames(dat)<-c("Dependent","Independent", "Factor" )
dat$Dependent <- as.numeric (dat$Dependent)
dat$Independent <- as.numeric (dat$Independent)
dat$Factor <- as.factor (dat$Factor)
#create custom scale
myColors <- brewer.pal(4,"Set1") # Pal value must be the same as factor levels
names(myColors) <- levels(dat$Factor)
colScale <- scale_colour_manual(name = "Origin",values = myColors, labels=c("Australia", "NG", "Americas"))
#Plot regression
p <- ggplot(dat, aes(log(Dependent), log(Independent), colour = Factor)) + geom_point() + geom_smooth(method = "lm", se = FALSE)
p1 <- p + colScale + labs(tag = '', title="Origin model", subtitle = 'NG and American Marsupials have larger relative brains', caption ='t=2.9, p=0.003, df=172', x ="Body Size", y = "Brain Size", fill = "Origin")
p1
## manually adjust the slope and intercept from the pgls
p <- ggplot(dat, aes(log(Dependent), log(Independent))) +
geom_point() +
scale_y_continuous(limits=c(-3, 5)) +
scale_x_continuous(limits=c(0, 12)) #+ geom_smooth(method = "lm", se = FALSE#)
p1 <- p + geom_abline(intercept = -2.17, slope = 0.574, color="blue", size=1) +
labs(
tag = '',
title="Brain - Body Allometry",
subtitle = expression(paste('Brain size = -2.17 + Body mass'^'0.57')),
caption = expression(paste('R'^'2'*' = 0.9, F'['(1, 174)'] * ' = 1581, p < 0.0001')),
x ="Body Size", y = "Brain Size")
p1
# mention it carefully
# mean(abs(res1))
# [1] 0.5541467 --> residuals mammals no marsupials (Isler)
# mean(abs(res))
# [1] 0.2408462 --> residuals my datatset
